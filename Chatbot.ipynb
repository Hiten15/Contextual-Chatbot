{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Stran\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'greeting',\n",
       "   'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day'],\n",
       "   'responses': ['Hello, thanks for visiting',\n",
       "    'Hi there, how can I help?',\n",
       "    'Hi, what can i do for you?'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'goodbye',\n",
       "   'patterns': ['Bye', 'See you later', 'Goodbye'],\n",
       "   'responses': ['See you later, thanks for visiting',\n",
       "    'Have a nice day',\n",
       "    'Bye! Come back again soon.']},\n",
       "  {'tag': 'thanks',\n",
       "   'patterns': ['Thanks', 'Thank you', \"That's helpful\"],\n",
       "   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n",
       "  {'tag': 'invest',\n",
       "   'patterns': ['I want to invest',\n",
       "    'How can i invest?',\n",
       "    'How to invest money ?',\n",
       "    'How much money can i invest? '],\n",
       "   'responses': ['You can invest in Stocks, Mutual Funds, SIP. To invest click the link below',\n",
       "    'To check our investment methods please click below.']},\n",
       "  {'tag': 'market',\n",
       "   'patterns': ['What is the market today?',\n",
       "    \"What are today's highlights\",\n",
       "    \"Today's nifty value\"],\n",
       "   'responses': [\"Please click on below link to see today's market\",\n",
       "    'You can check the market by clicking the below link.']},\n",
       "  {'tag': 'payments',\n",
       "   'patterns': ['Through which methods can i pay',\n",
       "    'Do you accept card?',\n",
       "    'Are you cash only?',\n",
       "    'How to do payments? ',\n",
       "    'What are the payments method'],\n",
       "   'responses': ['We accept payments through Debit or Credit cards,Online Banking and UPI',\n",
       "    'We accept most major credit cards']},\n",
       "  {'tag': 'account',\n",
       "   'patterns': ['How to open a trading account ?',\n",
       "    'How to open account ?',\n",
       "    'How to open a deemat account ?'],\n",
       "   'responses': ['Click on the below link, and fill in your details.']},\n",
       "  {'tag': 'close',\n",
       "   'patterns': ['How to close my account ?',\n",
       "    'How can i close my deemat account ?',\n",
       "    'How can i close my trading account ?'],\n",
       "   'responses': ['Closing a demat account involves visiting the DP office or branch by any of the demat account holders and submission of requisite form and documents']},\n",
       "  {'tag': 'withdraw',\n",
       "   'patterns': ['How can i withdraw funds ?'],\n",
       "   'responses': ['Click on below link to withdraw your funds.']}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []      #it will contain all words\n",
    "classes = []    #it will contain all tags\n",
    "documents = []  #it will contain all words with their corresponding tags\n",
    "ignore = ['?','.']\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize words\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        # add word to the words list\n",
    "        words.extend(w)\n",
    "        # add words to documents\n",
    "        documents.append((w, intent['tag']))\n",
    "        # add tags to classes\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " 'Is',\n",
       " 'anyone',\n",
       " 'there',\n",
       " '?',\n",
       " 'Hello',\n",
       " 'Good',\n",
       " 'day',\n",
       " 'Bye',\n",
       " 'See',\n",
       " 'you',\n",
       " 'later',\n",
       " 'Goodbye',\n",
       " 'Thanks',\n",
       " 'Thank',\n",
       " 'you',\n",
       " 'That',\n",
       " \"'s\",\n",
       " 'helpful',\n",
       " 'I',\n",
       " 'want',\n",
       " 'to',\n",
       " 'invest',\n",
       " 'How',\n",
       " 'can',\n",
       " 'i',\n",
       " 'invest',\n",
       " '?',\n",
       " 'How',\n",
       " 'to',\n",
       " 'invest',\n",
       " 'money',\n",
       " '?',\n",
       " 'How',\n",
       " 'much',\n",
       " 'money',\n",
       " 'can',\n",
       " 'i',\n",
       " 'invest',\n",
       " '?',\n",
       " 'What',\n",
       " 'is',\n",
       " 'the',\n",
       " 'market',\n",
       " 'today',\n",
       " '?',\n",
       " 'What',\n",
       " 'are',\n",
       " 'today',\n",
       " \"'s\",\n",
       " 'highlights',\n",
       " 'Today',\n",
       " \"'s\",\n",
       " 'nifty',\n",
       " 'value',\n",
       " 'Through',\n",
       " 'which',\n",
       " 'methods',\n",
       " 'can',\n",
       " 'i',\n",
       " 'pay',\n",
       " 'Do',\n",
       " 'you',\n",
       " 'accept',\n",
       " 'card',\n",
       " '?',\n",
       " 'Are',\n",
       " 'you',\n",
       " 'cash',\n",
       " 'only',\n",
       " '?',\n",
       " 'How',\n",
       " 'to',\n",
       " 'do',\n",
       " 'payments',\n",
       " '?',\n",
       " 'What',\n",
       " 'are',\n",
       " 'the',\n",
       " 'payments',\n",
       " 'method',\n",
       " 'How',\n",
       " 'to',\n",
       " 'open',\n",
       " 'a',\n",
       " 'trading',\n",
       " 'account',\n",
       " '?',\n",
       " 'How',\n",
       " 'to',\n",
       " 'open',\n",
       " 'account',\n",
       " '?',\n",
       " 'How',\n",
       " 'to',\n",
       " 'open',\n",
       " 'a',\n",
       " 'deemat',\n",
       " 'account',\n",
       " '?',\n",
       " 'How',\n",
       " 'to',\n",
       " 'close',\n",
       " 'my',\n",
       " 'account',\n",
       " '?',\n",
       " 'How',\n",
       " 'can',\n",
       " 'i',\n",
       " 'close',\n",
       " 'my',\n",
       " 'deemat',\n",
       " 'account',\n",
       " '?',\n",
       " 'How',\n",
       " 'can',\n",
       " 'i',\n",
       " 'close',\n",
       " 'my',\n",
       " 'trading',\n",
       " 'account',\n",
       " '?',\n",
       " 'How',\n",
       " 'can',\n",
       " 'i',\n",
       " 'withdraw',\n",
       " 'funds',\n",
       " '?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greeting',\n",
       " 'goodbye',\n",
       " 'thanks',\n",
       " 'invest',\n",
       " 'market',\n",
       " 'payments',\n",
       " 'account',\n",
       " 'close',\n",
       " 'withdraw']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Hi'], 'greeting'),\n",
       " (['How', 'are', 'you'], 'greeting'),\n",
       " (['Is', 'anyone', 'there', '?'], 'greeting'),\n",
       " (['Hello'], 'greeting'),\n",
       " (['Good', 'day'], 'greeting'),\n",
       " (['Bye'], 'goodbye'),\n",
       " (['See', 'you', 'later'], 'goodbye'),\n",
       " (['Goodbye'], 'goodbye'),\n",
       " (['Thanks'], 'thanks'),\n",
       " (['Thank', 'you'], 'thanks'),\n",
       " (['That', \"'s\", 'helpful'], 'thanks'),\n",
       " (['I', 'want', 'to', 'invest'], 'invest'),\n",
       " (['How', 'can', 'i', 'invest', '?'], 'invest'),\n",
       " (['How', 'to', 'invest', 'money', '?'], 'invest'),\n",
       " (['How', 'much', 'money', 'can', 'i', 'invest', '?'], 'invest'),\n",
       " (['What', 'is', 'the', 'market', 'today', '?'], 'market'),\n",
       " (['What', 'are', 'today', \"'s\", 'highlights'], 'market'),\n",
       " (['Today', \"'s\", 'nifty', 'value'], 'market'),\n",
       " (['Through', 'which', 'methods', 'can', 'i', 'pay'], 'payments'),\n",
       " (['Do', 'you', 'accept', 'card', '?'], 'payments'),\n",
       " (['Are', 'you', 'cash', 'only', '?'], 'payments'),\n",
       " (['How', 'to', 'do', 'payments', '?'], 'payments'),\n",
       " (['What', 'are', 'the', 'payments', 'method'], 'payments'),\n",
       " (['How', 'to', 'open', 'a', 'trading', 'account', '?'], 'account'),\n",
       " (['How', 'to', 'open', 'account', '?'], 'account'),\n",
       " (['How', 'to', 'open', 'a', 'deemat', 'account', '?'], 'account'),\n",
       " (['How', 'to', 'close', 'my', 'account', '?'], 'close'),\n",
       " (['How', 'can', 'i', 'close', 'my', 'deemat', 'account', '?'], 'close'),\n",
       " (['How', 'can', 'i', 'close', 'my', 'trading', 'account', '?'], 'close'),\n",
       " (['How', 'can', 'i', 'withdraw', 'funds', '?'], 'withdraw')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n",
    "words = sorted(list(set(words)))             #removing duplicates using set,set gives answer as a dictionary so we have to convert it intp a list\n",
    "\n",
    "# remove duplicate classes\n",
    "classes = sorted(list(set(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"'s\",\n",
       " 'a',\n",
       " 'accept',\n",
       " 'account',\n",
       " 'anyon',\n",
       " 'are',\n",
       " 'bye',\n",
       " 'can',\n",
       " 'card',\n",
       " 'cash',\n",
       " 'close',\n",
       " 'day',\n",
       " 'deemat',\n",
       " 'do',\n",
       " 'fund',\n",
       " 'good',\n",
       " 'goodby',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hi',\n",
       " 'highlight',\n",
       " 'how',\n",
       " 'i',\n",
       " 'invest',\n",
       " 'is',\n",
       " 'later',\n",
       " 'market',\n",
       " 'method',\n",
       " 'money',\n",
       " 'much',\n",
       " 'my',\n",
       " 'nifti',\n",
       " 'onli',\n",
       " 'open',\n",
       " 'pay',\n",
       " 'payment',\n",
       " 'see',\n",
       " 'thank',\n",
       " 'that',\n",
       " 'the',\n",
       " 'there',\n",
       " 'through',\n",
       " 'to',\n",
       " 'today',\n",
       " 'trade',\n",
       " 'valu',\n",
       " 'want',\n",
       " 'what',\n",
       " 'which',\n",
       " 'withdraw',\n",
       " 'you']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(words))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['account',\n",
       " 'close',\n",
       " 'goodbye',\n",
       " 'greeting',\n",
       " 'invest',\n",
       " 'market',\n",
       " 'payments',\n",
       " 'thanks',\n",
       " 'withdraw']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(classes))\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "output = []\n",
    "# create an empty array for output\n",
    "output_empty = [0] * len(classes)   #array with all 0 and of size len(classes)\n",
    "\n",
    "for doc in documents:\n",
    "    # initialize bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # stemming each word\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    # output is '1' for current tag and '0' for rest of other tags\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-d0b70e6f3886>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training = np.array(training)\n"
     ]
    }
   ],
   "source": [
    "# shuffling features\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "train_x = list(training[:,0])     #contains all patterns\n",
    "train_y = list(training[:,1])     #contains ki ek pattern konse tag ka hai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples\n",
      "Epoch 1/400\n",
      "30/30 [==============================] - 2s 74ms/sample - loss: 2.2553 - acc: 0.1000\n",
      "Epoch 2/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 2.2817 - acc: 0.1000\n",
      "Epoch 3/400\n",
      "30/30 [==============================] - 0s 904us/sample - loss: 2.3224 - acc: 0.0333\n",
      "Epoch 4/400\n",
      "30/30 [==============================] - 0s 985us/sample - loss: 2.2432 - acc: 0.0667\n",
      "Epoch 5/400\n",
      "30/30 [==============================] - 0s 884us/sample - loss: 2.2438 - acc: 0.0667\n",
      "Epoch 6/400\n",
      "30/30 [==============================] - 0s 891us/sample - loss: 2.2349 - acc: 0.0667\n",
      "Epoch 7/400\n",
      "30/30 [==============================] - 0s 833us/sample - loss: 2.1903 - acc: 0.1000\n",
      "Epoch 8/400\n",
      "30/30 [==============================] - 0s 850us/sample - loss: 2.2047 - acc: 0.1333\n",
      "Epoch 9/400\n",
      "30/30 [==============================] - 0s 850us/sample - loss: 2.2165 - acc: 0.1000\n",
      "Epoch 10/400\n",
      "30/30 [==============================] - 0s 862us/sample - loss: 2.1293 - acc: 0.2333\n",
      "Epoch 11/400\n",
      "30/30 [==============================] - 0s 834us/sample - loss: 2.1223 - acc: 0.1667\n",
      "Epoch 12/400\n",
      "30/30 [==============================] - 0s 875us/sample - loss: 2.0787 - acc: 0.2000\n",
      "Epoch 13/400\n",
      "30/30 [==============================] - 0s 901us/sample - loss: 2.1375 - acc: 0.1333\n",
      "Epoch 14/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 2.1052 - acc: 0.3000\n",
      "Epoch 15/400\n",
      "30/30 [==============================] - 0s 772us/sample - loss: 2.0725 - acc: 0.3000\n",
      "Epoch 16/400\n",
      "30/30 [==============================] - 0s 691us/sample - loss: 2.0618 - acc: 0.2333\n",
      "Epoch 17/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 2.1455 - acc: 0.2000\n",
      "Epoch 18/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 2.1041 - acc: 0.2667\n",
      "Epoch 19/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 2.0878 - acc: 0.1333\n",
      "Epoch 20/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 2.0950 - acc: 0.2333\n",
      "Epoch 21/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 2.0840 - acc: 0.1333\n",
      "Epoch 22/400\n",
      "30/30 [==============================] - 0s 787us/sample - loss: 2.0638 - acc: 0.2000\n",
      "Epoch 23/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 1.9822 - acc: 0.3333\n",
      "Epoch 24/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 2.0464 - acc: 0.4333\n",
      "Epoch 25/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 2.0524 - acc: 0.1333\n",
      "Epoch 26/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 2.0322 - acc: 0.3333\n",
      "Epoch 27/400\n",
      "30/30 [==============================] - 0s 735us/sample - loss: 2.0644 - acc: 0.3000\n",
      "Epoch 28/400\n",
      "30/30 [==============================] - 0s 774us/sample - loss: 1.9861 - acc: 0.2667\n",
      "Epoch 29/400\n",
      "30/30 [==============================] - 0s 747us/sample - loss: 2.0126 - acc: 0.3667\n",
      "Epoch 30/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 2.0286 - acc: 0.2667\n",
      "Epoch 31/400\n",
      "30/30 [==============================] - 0s 703us/sample - loss: 1.9819 - acc: 0.2667\n",
      "Epoch 32/400\n",
      "30/30 [==============================] - 0s 736us/sample - loss: 1.9318 - acc: 0.4000\n",
      "Epoch 33/400\n",
      "30/30 [==============================] - 0s 735us/sample - loss: 1.9658 - acc: 0.3667\n",
      "Epoch 34/400\n",
      "30/30 [==============================] - 0s 752us/sample - loss: 1.9513 - acc: 0.4000\n",
      "Epoch 35/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.9798 - acc: 0.4000\n",
      "Epoch 36/400\n",
      "30/30 [==============================] - 0s 732us/sample - loss: 2.0103 - acc: 0.3000\n",
      "Epoch 37/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.9981 - acc: 0.3333\n",
      "Epoch 38/400\n",
      "30/30 [==============================] - 0s 721us/sample - loss: 1.9514 - acc: 0.3333\n",
      "Epoch 39/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 1.9055 - acc: 0.4333\n",
      "Epoch 40/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 1.9244 - acc: 0.3667\n",
      "Epoch 41/400\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.8272 - acc: 0.5000\n",
      "Epoch 42/400\n",
      "30/30 [==============================] - 0s 1000us/sample - loss: 1.8927 - acc: 0.2667\n",
      "Epoch 43/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.9166 - acc: 0.3667\n",
      "Epoch 44/400\n",
      "30/30 [==============================] - 0s 684us/sample - loss: 1.8865 - acc: 0.3333\n",
      "Epoch 45/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 1.8489 - acc: 0.5000\n",
      "Epoch 46/400\n",
      "30/30 [==============================] - 0s 773us/sample - loss: 1.8452 - acc: 0.4667\n",
      "Epoch 47/400\n",
      "30/30 [==============================] - 0s 750us/sample - loss: 1.8493 - acc: 0.5000\n",
      "Epoch 48/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 1.8996 - acc: 0.2667\n",
      "Epoch 49/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 1.8876 - acc: 0.3667\n",
      "Epoch 50/400\n",
      "30/30 [==============================] - 0s 749us/sample - loss: 1.7720 - acc: 0.5333\n",
      "Epoch 51/400\n",
      "30/30 [==============================] - 0s 693us/sample - loss: 1.9395 - acc: 0.4000\n",
      "Epoch 52/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 1.7329 - acc: 0.4667\n",
      "Epoch 53/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 1.6855 - acc: 0.5667\n",
      "Epoch 54/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.8201 - acc: 0.5000\n",
      "Epoch 55/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 1.7151 - acc: 0.4000\n",
      "Epoch 56/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 1.7603 - acc: 0.5333\n",
      "Epoch 57/400\n",
      "30/30 [==============================] - 0s 739us/sample - loss: 1.8415 - acc: 0.4000\n",
      "Epoch 58/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.8014 - acc: 0.4000\n",
      "Epoch 59/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.8150 - acc: 0.4000\n",
      "Epoch 60/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.7565 - acc: 0.4667\n",
      "Epoch 61/400\n",
      "30/30 [==============================] - 0s 735us/sample - loss: 1.7183 - acc: 0.4667\n",
      "Epoch 62/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 1.7101 - acc: 0.4667\n",
      "Epoch 63/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 1.6302 - acc: 0.5333\n",
      "Epoch 64/400\n",
      "30/30 [==============================] - 0s 933us/sample - loss: 1.7283 - acc: 0.5000\n",
      "Epoch 65/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.7217 - acc: 0.3667\n",
      "Epoch 66/400\n",
      "30/30 [==============================] - 0s 754us/sample - loss: 1.7042 - acc: 0.4667\n",
      "Epoch 67/400\n",
      "30/30 [==============================] - 0s 984us/sample - loss: 1.7565 - acc: 0.4000\n",
      "Epoch 68/400\n",
      "30/30 [==============================] - 0s 872us/sample - loss: 1.7362 - acc: 0.4333\n",
      "Epoch 69/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 1.5223 - acc: 0.4667\n",
      "Epoch 70/400\n",
      "30/30 [==============================] - 0s 967us/sample - loss: 1.5852 - acc: 0.5333\n",
      "Epoch 71/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.5435 - acc: 0.6667\n",
      "Epoch 72/400\n",
      "30/30 [==============================] - 0s 968us/sample - loss: 1.6695 - acc: 0.4667\n",
      "Epoch 73/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.7089 - acc: 0.3333\n",
      "Epoch 74/400\n",
      "30/30 [==============================] - 0s 822us/sample - loss: 1.6057 - acc: 0.5333\n",
      "Epoch 75/400\n",
      "30/30 [==============================] - 0s 832us/sample - loss: 1.6767 - acc: 0.5000\n",
      "Epoch 76/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 1.4957 - acc: 0.6000\n",
      "Epoch 77/400\n",
      "30/30 [==============================] - 0s 1000us/sample - loss: 1.5056 - acc: 0.5667\n",
      "Epoch 78/400\n",
      "30/30 [==============================] - 0s 801us/sample - loss: 1.5260 - acc: 0.6000\n",
      "Epoch 79/400\n",
      "30/30 [==============================] - 0s 952us/sample - loss: 1.6499 - acc: 0.4333\n",
      "Epoch 80/400\n",
      "30/30 [==============================] - 0s 751us/sample - loss: 1.6943 - acc: 0.3000\n",
      "Epoch 81/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 1.5468 - acc: 0.4667\n",
      "Epoch 82/400\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.7053 - acc: 0.5667\n",
      "Epoch 83/400\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.5025 - acc: 0.6000\n",
      "Epoch 84/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.4602 - acc: 0.6667\n",
      "Epoch 85/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 1.5236 - acc: 0.6333\n",
      "Epoch 86/400\n",
      "30/30 [==============================] - 0s 723us/sample - loss: 1.5548 - acc: 0.6000\n",
      "Epoch 87/400\n",
      "30/30 [==============================] - 0s 834us/sample - loss: 1.5477 - acc: 0.5667\n",
      "Epoch 88/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 1.6174 - acc: 0.5000\n",
      "Epoch 89/400\n",
      "30/30 [==============================] - 0s 867us/sample - loss: 1.4987 - acc: 0.5333\n",
      "Epoch 90/400\n",
      "30/30 [==============================] - 0s 933us/sample - loss: 1.5279 - acc: 0.5667\n",
      "Epoch 91/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.4468 - acc: 0.6000\n",
      "Epoch 92/400\n",
      "30/30 [==============================] - 0s 906us/sample - loss: 1.4313 - acc: 0.5667\n",
      "Epoch 93/400\n",
      "30/30 [==============================] - 0s 867us/sample - loss: 1.4777 - acc: 0.5667\n",
      "Epoch 94/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 1.3827 - acc: 0.5000\n",
      "Epoch 95/400\n",
      "30/30 [==============================] - 0s 933us/sample - loss: 1.3958 - acc: 0.6000\n",
      "Epoch 96/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 1.2750 - acc: 0.6667\n",
      "Epoch 97/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 1.2715 - acc: 0.6667\n",
      "Epoch 98/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 1.3753 - acc: 0.6333\n",
      "Epoch 99/400\n",
      "30/30 [==============================] - 0s 900us/sample - loss: 1.3674 - acc: 0.5333\n",
      "Epoch 100/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.3834 - acc: 0.6333\n",
      "Epoch 101/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.3697 - acc: 0.6000\n",
      "Epoch 102/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.3555 - acc: 0.5667\n",
      "Epoch 103/400\n",
      "30/30 [==============================] - 0s 755us/sample - loss: 1.3095 - acc: 0.6000\n",
      "Epoch 104/400\n",
      "30/30 [==============================] - 0s 725us/sample - loss: 1.3914 - acc: 0.5667\n",
      "Epoch 105/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 1.3233 - acc: 0.6667\n",
      "Epoch 106/400\n",
      "30/30 [==============================] - 0s 732us/sample - loss: 1.3969 - acc: 0.5000\n",
      "Epoch 107/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 1.5313 - acc: 0.4333\n",
      "Epoch 108/400\n",
      "30/30 [==============================] - 0s 684us/sample - loss: 1.3220 - acc: 0.6333\n",
      "Epoch 109/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.3292 - acc: 0.6333\n",
      "Epoch 110/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 1.3982 - acc: 0.6000\n",
      "Epoch 111/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.3587 - acc: 0.5667\n",
      "Epoch 112/400\n",
      "30/30 [==============================] - 0s 723us/sample - loss: 1.2360 - acc: 0.6667\n",
      "Epoch 113/400\n",
      "30/30 [==============================] - 0s 735us/sample - loss: 1.2489 - acc: 0.7333\n",
      "Epoch 114/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 1.1398 - acc: 0.8333\n",
      "Epoch 115/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.2870 - acc: 0.6333\n",
      "Epoch 116/400\n",
      "30/30 [==============================] - 0s 716us/sample - loss: 1.2972 - acc: 0.6667\n",
      "Epoch 117/400\n",
      "30/30 [==============================] - 0s 735us/sample - loss: 1.1379 - acc: 0.7333\n",
      "Epoch 118/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.1932 - acc: 0.6667\n",
      "Epoch 119/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 1.2155 - acc: 0.5667\n",
      "Epoch 120/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.1959 - acc: 0.6333\n",
      "Epoch 121/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 1.2590 - acc: 0.6667\n",
      "Epoch 122/400\n",
      "30/30 [==============================] - 0s 686us/sample - loss: 1.1234 - acc: 0.7667\n",
      "Epoch 123/400\n",
      "30/30 [==============================] - 0s 685us/sample - loss: 1.2208 - acc: 0.7000\n",
      "Epoch 124/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 1.0376 - acc: 0.7000\n",
      "Epoch 125/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 1.2098 - acc: 0.7000\n",
      "Epoch 126/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 1.3915 - acc: 0.6333\n",
      "Epoch 127/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.1022 - acc: 0.7333\n",
      "Epoch 128/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 1.0627 - acc: 0.8000\n",
      "Epoch 129/400\n",
      "30/30 [==============================] - 0s 769us/sample - loss: 1.2753 - acc: 0.6667\n",
      "Epoch 130/400\n",
      "30/30 [==============================] - 0s 784us/sample - loss: 0.9364 - acc: 0.8000\n",
      "Epoch 131/400\n",
      "30/30 [==============================] - 0s 801us/sample - loss: 1.2114 - acc: 0.6333\n",
      "Epoch 132/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.0596 - acc: 0.7667\n",
      "Epoch 133/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 1.1744 - acc: 0.6667\n",
      "Epoch 134/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 1.1093 - acc: 0.7667\n",
      "Epoch 135/400\n",
      "30/30 [==============================] - 0s 718us/sample - loss: 1.0479 - acc: 0.7333\n",
      "Epoch 136/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 1.1431 - acc: 0.7333\n",
      "Epoch 137/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 1.1210 - acc: 0.6667\n",
      "Epoch 138/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.0422 - acc: 0.7000\n",
      "Epoch 139/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.9915 - acc: 0.8667\n",
      "Epoch 140/400\n",
      "30/30 [==============================] - 0s 718us/sample - loss: 1.1617 - acc: 0.6667\n",
      "Epoch 141/400\n",
      "30/30 [==============================] - 0s 731us/sample - loss: 1.1294 - acc: 0.7000\n",
      "Epoch 142/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.1762 - acc: 0.7000\n",
      "Epoch 143/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 1.2265 - acc: 0.7000\n",
      "Epoch 144/400\n",
      "30/30 [==============================] - 0s 799us/sample - loss: 1.0247 - acc: 0.7333\n",
      "Epoch 145/400\n",
      "30/30 [==============================] - 0s 867us/sample - loss: 1.0251 - acc: 0.7000\n",
      "Epoch 146/400\n",
      "30/30 [==============================] - 0s 900us/sample - loss: 0.9676 - acc: 0.7667\n",
      "Epoch 147/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.1199 - acc: 0.6000\n",
      "Epoch 148/400\n",
      "30/30 [==============================] - 0s 718us/sample - loss: 0.9985 - acc: 0.8000\n",
      "Epoch 149/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 0.9100 - acc: 0.8333\n",
      "Epoch 150/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 1.0847 - acc: 0.7333\n",
      "Epoch 151/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 1.1425 - acc: 0.6333\n",
      "Epoch 152/400\n",
      "30/30 [==============================] - 0s 707us/sample - loss: 0.9664 - acc: 0.7333\n",
      "Epoch 153/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.8847 - acc: 0.9000\n",
      "Epoch 154/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.9445 - acc: 0.7667\n",
      "Epoch 155/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.8624 - acc: 0.8333\n",
      "Epoch 156/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.8994 - acc: 0.8333\n",
      "Epoch 157/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.9466 - acc: 0.7333\n",
      "Epoch 158/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 0.8389 - acc: 0.8000\n",
      "Epoch 159/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 0.9760 - acc: 0.7333\n",
      "Epoch 160/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 1.0402 - acc: 0.7667\n",
      "Epoch 161/400\n",
      "30/30 [==============================] - 0s 705us/sample - loss: 0.8156 - acc: 0.8333\n",
      "Epoch 162/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.9523 - acc: 0.7333\n",
      "Epoch 163/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 0.8885 - acc: 0.8333\n",
      "Epoch 164/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.7778 - acc: 0.7333\n",
      "Epoch 165/400\n",
      "30/30 [==============================] - 0s 766us/sample - loss: 0.7555 - acc: 0.7667\n",
      "Epoch 166/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 0.8566 - acc: 0.7333\n",
      "Epoch 167/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 0.8654 - acc: 0.7000\n",
      "Epoch 168/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 0.9483 - acc: 0.7667\n",
      "Epoch 169/400\n",
      "30/30 [==============================] - 0s 804us/sample - loss: 0.7991 - acc: 0.8667\n",
      "Epoch 170/400\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.9652 - acc: 0.7667\n",
      "Epoch 171/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.8181 - acc: 0.7667\n",
      "Epoch 172/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.8401 - acc: 0.8333\n",
      "Epoch 173/400\n",
      "30/30 [==============================] - 0s 848us/sample - loss: 0.8004 - acc: 0.8667\n",
      "Epoch 174/400\n",
      "30/30 [==============================] - 0s 868us/sample - loss: 0.6847 - acc: 0.8333\n",
      "Epoch 175/400\n",
      "30/30 [==============================] - 0s 753us/sample - loss: 0.8758 - acc: 0.7667\n",
      "Epoch 176/400\n",
      "30/30 [==============================] - 0s 811us/sample - loss: 0.7766 - acc: 0.8667\n",
      "Epoch 177/400\n",
      "30/30 [==============================] - 0s 833us/sample - loss: 0.7720 - acc: 0.7333\n",
      "Epoch 178/400\n",
      "30/30 [==============================] - 0s 834us/sample - loss: 0.8723 - acc: 0.8000\n",
      "Epoch 179/400\n",
      "30/30 [==============================] - 0s 834us/sample - loss: 0.7893 - acc: 0.7000\n",
      "Epoch 180/400\n",
      "30/30 [==============================] - 0s 805us/sample - loss: 0.8495 - acc: 0.8333\n",
      "Epoch 181/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.8391 - acc: 0.7667\n",
      "Epoch 182/400\n",
      "30/30 [==============================] - 0s 834us/sample - loss: 0.8451 - acc: 0.7667\n",
      "Epoch 183/400\n",
      "30/30 [==============================] - 0s 802us/sample - loss: 0.8130 - acc: 0.8000\n",
      "Epoch 184/400\n",
      "30/30 [==============================] - 0s 820us/sample - loss: 0.7836 - acc: 0.9000\n",
      "Epoch 185/400\n",
      "30/30 [==============================] - 0s 761us/sample - loss: 0.7810 - acc: 0.8667\n",
      "Epoch 186/400\n",
      "30/30 [==============================] - 0s 771us/sample - loss: 0.8289 - acc: 0.8667\n",
      "Epoch 187/400\n",
      "30/30 [==============================] - 0s 833us/sample - loss: 0.7636 - acc: 0.8000\n",
      "Epoch 188/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.7898 - acc: 0.7333\n",
      "Epoch 189/400\n",
      "30/30 [==============================] - 0s 760us/sample - loss: 0.8114 - acc: 0.8667\n",
      "Epoch 190/400\n",
      "30/30 [==============================] - 0s 772us/sample - loss: 0.7196 - acc: 0.8667\n",
      "Epoch 191/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.7804 - acc: 0.8000\n",
      "Epoch 192/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.6397 - acc: 0.9333\n",
      "Epoch 193/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.7345 - acc: 0.8333\n",
      "Epoch 194/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.8110 - acc: 0.8000\n",
      "Epoch 195/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.7534 - acc: 0.7667\n",
      "Epoch 196/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.6691 - acc: 0.8667\n",
      "Epoch 197/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.7450 - acc: 0.8333\n",
      "Epoch 198/400\n",
      "30/30 [==============================] - 0s 719us/sample - loss: 0.5598 - acc: 0.9000\n",
      "Epoch 199/400\n",
      "30/30 [==============================] - 0s 790us/sample - loss: 0.6202 - acc: 0.7667\n",
      "Epoch 200/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.6457 - acc: 0.9000\n",
      "Epoch 201/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.5267 - acc: 0.9667\n",
      "Epoch 202/400\n",
      "30/30 [==============================] - 0s 833us/sample - loss: 0.6691 - acc: 0.8000\n",
      "Epoch 203/400\n",
      "30/30 [==============================] - 0s 766us/sample - loss: 0.5911 - acc: 0.9333\n",
      "Epoch 204/400\n",
      "30/30 [==============================] - 0s 752us/sample - loss: 0.7802 - acc: 0.8000\n",
      "Epoch 205/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.8949 - acc: 0.7333\n",
      "Epoch 206/400\n",
      "30/30 [==============================] - 0s 807us/sample - loss: 0.6266 - acc: 0.8333\n",
      "Epoch 207/400\n",
      "30/30 [==============================] - 0s 796us/sample - loss: 0.6882 - acc: 0.9000\n",
      "Epoch 208/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.6053 - acc: 0.8333\n",
      "Epoch 209/400\n",
      "30/30 [==============================] - 0s 833us/sample - loss: 0.5369 - acc: 0.9333\n",
      "Epoch 210/400\n",
      "30/30 [==============================] - 0s 893us/sample - loss: 0.5899 - acc: 0.9000\n",
      "Epoch 211/400\n",
      "30/30 [==============================] - 0s 852us/sample - loss: 0.6317 - acc: 0.9000\n",
      "Epoch 212/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.7250 - acc: 0.8333\n",
      "Epoch 213/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.5783 - acc: 0.9667\n",
      "Epoch 214/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.7241 - acc: 0.8667\n",
      "Epoch 215/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.7373 - acc: 0.7667\n",
      "Epoch 216/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.5958 - acc: 0.8667\n",
      "Epoch 217/400\n",
      "30/30 [==============================] - 0s 715us/sample - loss: 0.5611 - acc: 0.9000\n",
      "Epoch 218/400\n",
      "30/30 [==============================] - 0s 760us/sample - loss: 0.6420 - acc: 0.8333\n",
      "Epoch 219/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.6842 - acc: 0.9000\n",
      "Epoch 220/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.6934 - acc: 0.7667\n",
      "Epoch 221/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.7116 - acc: 0.8000\n",
      "Epoch 222/400\n",
      "30/30 [==============================] - 0s 743us/sample - loss: 0.6404 - acc: 0.8000\n",
      "Epoch 223/400\n",
      "30/30 [==============================] - 0s 752us/sample - loss: 0.5081 - acc: 0.8333\n",
      "Epoch 224/400\n",
      "30/30 [==============================] - 0s 766us/sample - loss: 0.6024 - acc: 0.8333\n",
      "Epoch 225/400\n",
      "30/30 [==============================] - 0s 732us/sample - loss: 0.5089 - acc: 0.9000\n",
      "Epoch 226/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.5385 - acc: 0.8333\n",
      "Epoch 227/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.7322 - acc: 0.8333\n",
      "Epoch 228/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 0.6504 - acc: 0.8333\n",
      "Epoch 229/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.5316 - acc: 0.9333\n",
      "Epoch 230/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.6331 - acc: 0.9000\n",
      "Epoch 231/400\n",
      "30/30 [==============================] - 0s 713us/sample - loss: 0.8028 - acc: 0.7667\n",
      "Epoch 232/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.4878 - acc: 0.9000\n",
      "Epoch 233/400\n",
      "30/30 [==============================] - 0s 710us/sample - loss: 0.6449 - acc: 0.7333\n",
      "Epoch 234/400\n",
      "30/30 [==============================] - 0s 717us/sample - loss: 0.4949 - acc: 0.8667\n",
      "Epoch 235/400\n",
      "30/30 [==============================] - 0s 748us/sample - loss: 0.5606 - acc: 0.8667\n",
      "Epoch 236/400\n",
      "30/30 [==============================] - 0s 900us/sample - loss: 0.5122 - acc: 0.9000\n",
      "Epoch 237/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.4746 - acc: 0.9000\n",
      "Epoch 238/400\n",
      "30/30 [==============================] - 0s 817us/sample - loss: 0.5863 - acc: 0.8667\n",
      "Epoch 239/400\n",
      "30/30 [==============================] - 0s 784us/sample - loss: 0.6361 - acc: 0.8000\n",
      "Epoch 240/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.5241 - acc: 0.9333\n",
      "Epoch 241/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.5792 - acc: 0.9333\n",
      "Epoch 242/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.5794 - acc: 0.8000\n",
      "Epoch 243/400\n",
      "30/30 [==============================] - 0s 900us/sample - loss: 0.5303 - acc: 0.8667\n",
      "Epoch 244/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 0.7295 - acc: 0.8333\n",
      "Epoch 245/400\n",
      "30/30 [==============================] - 0s 735us/sample - loss: 0.6450 - acc: 0.9000\n",
      "Epoch 246/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.4663 - acc: 0.9333\n",
      "Epoch 247/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.5606 - acc: 0.8000\n",
      "Epoch 248/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.5267 - acc: 0.9000\n",
      "Epoch 249/400\n",
      "30/30 [==============================] - 0s 753us/sample - loss: 0.7351 - acc: 0.8333\n",
      "Epoch 250/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.6763 - acc: 0.8667\n",
      "Epoch 251/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3397 - acc: 1.0000\n",
      "Epoch 252/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.5564 - acc: 0.8667\n",
      "Epoch 253/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.5190 - acc: 0.8667\n",
      "Epoch 254/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.4789 - acc: 0.9000\n",
      "Epoch 255/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.6742 - acc: 0.7667\n",
      "Epoch 256/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.3724 - acc: 0.9667\n",
      "Epoch 257/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.5202 - acc: 0.9333\n",
      "Epoch 258/400\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.3942 - acc: 0.9000\n",
      "Epoch 259/400\n",
      "30/30 [==============================] - 0s 776us/sample - loss: 0.6034 - acc: 0.8333\n",
      "Epoch 260/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.5527 - acc: 0.8667\n",
      "Epoch 261/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 0.5501 - acc: 0.8667\n",
      "Epoch 262/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.4517 - acc: 0.9000\n",
      "Epoch 263/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.5922 - acc: 0.8000\n",
      "Epoch 264/400\n",
      "30/30 [==============================] - 0s 758us/sample - loss: 0.4473 - acc: 0.9333\n",
      "Epoch 265/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.5037 - acc: 0.8000\n",
      "Epoch 266/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.4301 - acc: 1.0000\n",
      "Epoch 267/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.3335 - acc: 1.0000\n",
      "Epoch 268/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.3905 - acc: 0.9000\n",
      "Epoch 269/400\n",
      "30/30 [==============================] - 0s 677us/sample - loss: 0.4347 - acc: 0.8667\n",
      "Epoch 270/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 0.5629 - acc: 0.9000\n",
      "Epoch 271/400\n",
      "30/30 [==============================] - 0s 703us/sample - loss: 0.5603 - acc: 0.9000\n",
      "Epoch 272/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.4633 - acc: 0.9000\n",
      "Epoch 273/400\n",
      "30/30 [==============================] - 0s 667us/sample - loss: 0.3685 - acc: 0.9333\n",
      "Epoch 274/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.6269 - acc: 0.7333\n",
      "Epoch 275/400\n",
      "30/30 [==============================] - 0s 729us/sample - loss: 0.4948 - acc: 0.8333\n",
      "Epoch 276/400\n",
      "30/30 [==============================] - 0s 725us/sample - loss: 0.3469 - acc: 0.9333\n",
      "Epoch 277/400\n",
      "30/30 [==============================] - 0s 771us/sample - loss: 0.5133 - acc: 0.8000\n",
      "Epoch 278/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.4053 - acc: 0.9000\n",
      "Epoch 279/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.4857 - acc: 0.8667\n",
      "Epoch 280/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.4884 - acc: 0.8667\n",
      "Epoch 281/400\n",
      "30/30 [==============================] - 0s 719us/sample - loss: 0.4532 - acc: 0.8333\n",
      "Epoch 282/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.4002 - acc: 0.9667\n",
      "Epoch 283/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.4887 - acc: 0.8333\n",
      "Epoch 284/400\n",
      "30/30 [==============================] - 0s 722us/sample - loss: 0.4665 - acc: 0.8333\n",
      "Epoch 285/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.4516 - acc: 0.8333\n",
      "Epoch 286/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.4302 - acc: 0.9000\n",
      "Epoch 287/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 0.4532 - acc: 0.8667\n",
      "Epoch 288/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.4407 - acc: 0.9000\n",
      "Epoch 289/400\n",
      "30/30 [==============================] - 0s 817us/sample - loss: 0.3486 - acc: 0.9333\n",
      "Epoch 290/400\n",
      "30/30 [==============================] - 0s 751us/sample - loss: 0.4162 - acc: 0.9333\n",
      "Epoch 291/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 0.3209 - acc: 0.9667\n",
      "Epoch 292/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.3226 - acc: 1.0000\n",
      "Epoch 293/400\n",
      "30/30 [==============================] - 0s 717us/sample - loss: 0.5427 - acc: 0.9000\n",
      "Epoch 294/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3891 - acc: 0.9333\n",
      "Epoch 295/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 0.5015 - acc: 0.8667\n",
      "Epoch 296/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.3586 - acc: 0.9333\n",
      "Epoch 297/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.5482 - acc: 0.8667\n",
      "Epoch 298/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3549 - acc: 0.9333\n",
      "Epoch 299/400\n",
      "30/30 [==============================] - 0s 717us/sample - loss: 0.4127 - acc: 0.9667\n",
      "Epoch 300/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 0.3355 - acc: 0.9000\n",
      "Epoch 301/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.3400 - acc: 0.9333\n",
      "Epoch 302/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.3790 - acc: 0.9667\n",
      "Epoch 303/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.4248 - acc: 0.8667\n",
      "Epoch 304/400\n",
      "30/30 [==============================] - 0s 801us/sample - loss: 0.5145 - acc: 0.8667\n",
      "Epoch 305/400\n",
      "30/30 [==============================] - 0s 793us/sample - loss: 0.3361 - acc: 1.0000\n",
      "Epoch 306/400\n",
      "30/30 [==============================] - 0s 783us/sample - loss: 0.5686 - acc: 0.8333\n",
      "Epoch 307/400\n",
      "30/30 [==============================] - 0s 779us/sample - loss: 0.3746 - acc: 0.9000\n",
      "Epoch 308/400\n",
      "30/30 [==============================] - 0s 740us/sample - loss: 0.3065 - acc: 0.9667\n",
      "Epoch 309/400\n",
      "30/30 [==============================] - 0s 735us/sample - loss: 0.3990 - acc: 1.0000\n",
      "Epoch 310/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.4850 - acc: 0.9000\n",
      "Epoch 311/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.4517 - acc: 0.9333\n",
      "Epoch 312/400\n",
      "30/30 [==============================] - 0s 713us/sample - loss: 0.3171 - acc: 0.9000\n",
      "Epoch 313/400\n",
      "30/30 [==============================] - 0s 725us/sample - loss: 0.3305 - acc: 0.9667\n",
      "Epoch 314/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3766 - acc: 0.9000\n",
      "Epoch 315/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3209 - acc: 0.9667\n",
      "Epoch 316/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.3236 - acc: 0.9667\n",
      "Epoch 317/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 0.2333 - acc: 1.0000\n",
      "Epoch 318/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3477 - acc: 0.9333\n",
      "Epoch 319/400\n",
      "30/30 [==============================] - 0s 759us/sample - loss: 0.4121 - acc: 0.9667\n",
      "Epoch 320/400\n",
      "30/30 [==============================] - 0s 732us/sample - loss: 0.3145 - acc: 0.9667\n",
      "Epoch 321/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.5052 - acc: 0.8333\n",
      "Epoch 322/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 0.2733 - acc: 1.0000\n",
      "Epoch 323/400\n",
      "30/30 [==============================] - 0s 729us/sample - loss: 0.3272 - acc: 0.9667\n",
      "Epoch 324/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 0.3371 - acc: 0.9333\n",
      "Epoch 325/400\n",
      "30/30 [==============================] - 0s 731us/sample - loss: 0.2578 - acc: 0.9667\n",
      "Epoch 326/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.4374 - acc: 0.9333\n",
      "Epoch 327/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.2735 - acc: 1.0000\n",
      "Epoch 328/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.2587 - acc: 0.9667\n",
      "Epoch 329/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 0.3180 - acc: 0.9667\n",
      "Epoch 330/400\n",
      "30/30 [==============================] - 0s 704us/sample - loss: 0.4155 - acc: 0.9333\n",
      "Epoch 331/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.3927 - acc: 0.8667\n",
      "Epoch 332/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.4129 - acc: 0.9000\n",
      "Epoch 333/400\n",
      "30/30 [==============================] - 0s 834us/sample - loss: 0.3141 - acc: 0.9333\n",
      "Epoch 334/400\n",
      "30/30 [==============================] - 0s 738us/sample - loss: 0.2124 - acc: 0.9667\n",
      "Epoch 335/400\n",
      "30/30 [==============================] - 0s 702us/sample - loss: 0.2642 - acc: 0.9333\n",
      "Epoch 336/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.2975 - acc: 0.9667\n",
      "Epoch 337/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 0.2032 - acc: 1.0000\n",
      "Epoch 338/400\n",
      "30/30 [==============================] - 0s 773us/sample - loss: 0.3187 - acc: 0.9667\n",
      "Epoch 339/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3322 - acc: 0.9333\n",
      "Epoch 340/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 0.5682 - acc: 0.8333\n",
      "Epoch 341/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.1827 - acc: 1.0000\n",
      "Epoch 342/400\n",
      "30/30 [==============================] - 0s 757us/sample - loss: 0.3398 - acc: 0.9333\n",
      "Epoch 343/400\n",
      "30/30 [==============================] - 0s 757us/sample - loss: 0.4077 - acc: 0.8333\n",
      "Epoch 344/400\n",
      "30/30 [==============================] - 0s 672us/sample - loss: 0.3046 - acc: 0.9333\n",
      "Epoch 345/400\n",
      "30/30 [==============================] - 0s 723us/sample - loss: 0.2834 - acc: 0.9667\n",
      "Epoch 346/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.3041 - acc: 0.9667\n",
      "Epoch 347/400\n",
      "30/30 [==============================] - 0s 966us/sample - loss: 0.3982 - acc: 0.9333\n",
      "Epoch 348/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.2703 - acc: 1.0000\n",
      "Epoch 349/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.4021 - acc: 0.8333\n",
      "Epoch 350/400\n",
      "30/30 [==============================] - 0s 765us/sample - loss: 0.3727 - acc: 0.9000\n",
      "Epoch 351/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3784 - acc: 0.9000\n",
      "Epoch 352/400\n",
      "30/30 [==============================] - 0s 736us/sample - loss: 0.3050 - acc: 0.9000\n",
      "Epoch 353/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.3170 - acc: 0.9667\n",
      "Epoch 354/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.2484 - acc: 0.9333\n",
      "Epoch 355/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 0.2051 - acc: 0.9667\n",
      "Epoch 356/400\n",
      "30/30 [==============================] - 0s 724us/sample - loss: 0.2724 - acc: 0.9333\n",
      "Epoch 357/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.2610 - acc: 1.0000\n",
      "Epoch 358/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.2438 - acc: 0.9667\n",
      "Epoch 359/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.1883 - acc: 0.9667\n",
      "Epoch 360/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 0.2226 - acc: 0.9667\n",
      "Epoch 361/400\n",
      "30/30 [==============================] - 0s 771us/sample - loss: 0.4152 - acc: 0.9000\n",
      "Epoch 362/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3093 - acc: 0.9333\n",
      "Epoch 363/400\n",
      "30/30 [==============================] - 0s 735us/sample - loss: 0.2388 - acc: 0.9667\n",
      "Epoch 364/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.3637 - acc: 0.9333\n",
      "Epoch 365/400\n",
      "30/30 [==============================] - 0s 766us/sample - loss: 0.2763 - acc: 0.9333\n",
      "Epoch 366/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.2083 - acc: 1.0000\n",
      "Epoch 367/400\n",
      "30/30 [==============================] - 0s 667us/sample - loss: 0.2170 - acc: 1.0000\n",
      "Epoch 368/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 0.3390 - acc: 0.9333\n",
      "Epoch 369/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 0.3945 - acc: 0.9000\n",
      "Epoch 370/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.2106 - acc: 0.9667\n",
      "Epoch 371/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 0.3123 - acc: 0.9333\n",
      "Epoch 372/400\n",
      "30/30 [==============================] - 0s 768us/sample - loss: 0.3158 - acc: 0.9333\n",
      "Epoch 373/400\n",
      "30/30 [==============================] - 0s 720us/sample - loss: 0.1772 - acc: 0.9667\n",
      "Epoch 374/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.3099 - acc: 0.9667\n",
      "Epoch 375/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.2786 - acc: 0.9667\n",
      "Epoch 376/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 0.2109 - acc: 0.9667\n",
      "Epoch 377/400\n",
      "30/30 [==============================] - 0s 766us/sample - loss: 0.1879 - acc: 1.0000\n",
      "Epoch 378/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3334 - acc: 0.9000\n",
      "Epoch 379/400\n",
      "30/30 [==============================] - 0s 730us/sample - loss: 0.2835 - acc: 0.9667\n",
      "Epoch 380/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3259 - acc: 0.9000\n",
      "Epoch 381/400\n",
      "30/30 [==============================] - 0s 736us/sample - loss: 0.4353 - acc: 0.9333\n",
      "Epoch 382/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.2600 - acc: 0.9667\n",
      "Epoch 383/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.3802 - acc: 0.8667\n",
      "Epoch 384/400\n",
      "30/30 [==============================] - 0s 667us/sample - loss: 0.2376 - acc: 0.9667\n",
      "Epoch 385/400\n",
      "30/30 [==============================] - 0s 734us/sample - loss: 0.1914 - acc: 0.9333\n",
      "Epoch 386/400\n",
      "30/30 [==============================] - 0s 701us/sample - loss: 0.2849 - acc: 0.9333\n",
      "Epoch 387/400\n",
      "30/30 [==============================] - 0s 767us/sample - loss: 0.3755 - acc: 0.8667\n",
      "Epoch 388/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 0.2932 - acc: 1.0000\n",
      "Epoch 389/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.2229 - acc: 0.9667\n",
      "Epoch 390/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.3343 - acc: 0.9000\n",
      "Epoch 391/400\n",
      "30/30 [==============================] - 0s 700us/sample - loss: 0.1792 - acc: 1.0000\n",
      "Epoch 392/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.1959 - acc: 1.0000\n",
      "Epoch 393/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.2579 - acc: 0.9667\n",
      "Epoch 394/400\n",
      "30/30 [==============================] - 0s 1ms/sample - loss: 0.2440 - acc: 0.9667\n",
      "Epoch 395/400\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1926 - acc: 0.9667\n",
      "Epoch 396/400\n",
      "30/30 [==============================] - 0s 741us/sample - loss: 0.2197 - acc: 0.9333\n",
      "Epoch 397/400\n",
      "30/30 [==============================] - 0s 833us/sample - loss: 0.2494 - acc: 0.9333\n",
      "Epoch 398/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.2265 - acc: 1.0000\n",
      "Epoch 399/400\n",
      "30/30 [==============================] - 0s 733us/sample - loss: 0.2372 - acc: 0.9333\n",
      "Epoch 400/400\n",
      "30/30 [==============================] - 0s 800us/sample - loss: 0.2294 - acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20dc85c9460>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, input_shape=(len(train_x[0]),), activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(train_y[0]), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(np.array(train_x),np.array(train_y), epochs=400,batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               6656      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 585       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,497\n",
      "Trainable params: 15,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('chatbot_model.model',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('chatbot_model.h5',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open( \"training_data\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# restoring all the data structures\n",
    "data = pickle.load( open( \"training_data\", \"rb\" ) )\n",
    "words = data['words']\n",
    "classes = data['classes']\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as json_data:\n",
    "    intents = json.load(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Stran\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Users\\Stran\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "reconstructed_model = keras.models.load_model(\"chatbot_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating BOW from user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenizing the pattern\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stemming each word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# returning bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=False):\n",
    "    # tokenizing the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # generating bag of words\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):       #Enumerate() method adds a counter to an iterable and returns it in a form of enumerating object. This enumerated object can then be used directly for loops or converted into a list of tuples using the list() method\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(bow('How to invest?', words)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stran\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.2281616e-02, 9.7638805e-04, 1.5582094e-03, 2.2377812e-03,\n",
       "       9.7181803e-01, 8.7336375e-05, 1.0104647e-03, 9.6481259e-04,\n",
       "       9.0653915e-03], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = reconstructed_model.predict(np.array([bow('How to invest?', words)]))[0]   #[0] is added to convert 2d array to 1d\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 0.97181803]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ERROR_THRESHOLD = 0.25\n",
    "results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 0.97181803]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('invest', 0.97181803)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "return_list = []\n",
    "for r in results:\n",
    "    return_list.append((classes[r[0]], r[1]))\n",
    "return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_THRESHOLD = 0.30\n",
    "def classify(sentence):\n",
    "    # generate probabilities from the model\n",
    "    results = reconstructed_model.predict(np.array([bow(sentence, words)]))[0]\n",
    "    # filter out predictions below a threshold\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], r[1]))\n",
    "    # return tuple of intent and probability\n",
    "    return return_list\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    # if we have a classification then find the matching intent tag\n",
    "    if results:\n",
    "        # loop as long as there are matches to process\n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                # find a tag matching the first result\n",
    "                if i['tag'] == results[0][0]:\n",
    "                    # a random response from the intent\n",
    "                    return print(random.choice(i['responses']))\n",
    "\n",
    "            results.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('market', 0.98844993)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"What is the market today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please click on below link to see today's market\n"
     ]
    }
   ],
   "source": [
    "response(\"What is the market today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there, how can I help?\n"
     ]
    }
   ],
   "source": [
    "response(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, what can i do for you?\n"
     ]
    }
   ],
   "source": [
    "response(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To check our investment methods please click below.\n"
     ]
    }
   ],
   "source": [
    "response(\"How to invest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the below link, and fill in your details.\n"
     ]
    }
   ],
   "source": [
    "response(\"i want to open a account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing a demat account involves visiting the DP office or branch by any of the demat account holders and submission of requisite form and documents\n"
     ]
    }
   ],
   "source": [
    "response(\"Close my trading account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f79dc16612ed3b9a7ce36b5a9155bc44b35b73372061ffe8a80d501ba3cb37f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
